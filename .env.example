# Hevno环境配置示例文件
# 请复制此文件为 .env 并填入您的实际配置

# === Gemini 提供商配置 ===
# Google Gemini API 密钥，多个密钥用逗号分隔
GEMINI_API_KEYS="your-gemini-api-key-here,another-gemini-key"

# === 自定义 OpenAI 兼容提供商配置 ===
# 自定义提供商的基础 URL，例如 Groq、OpenAI、本地部署的服务等
OPENAI_CUSTOM_BASE_URL="https://api.openai.com"

# 自定义提供商的 API 密钥，多个密钥用逗号分隔
OPENAI_CUSTOM_API_KEYS="sk-your-openai-key-here,sk-another-key"

# (可选) 模型映射配置
# 格式1：简单的 key:value 格式，多个映射用逗号分隔
# OPENAI_CUSTOM_MODEL_MAPPING="gemini-proxy:gemini/gemini-1.5-pro,gpt4-proxy:gemini/gemini-1.5-flash"

# 格式2：JSON 格式（推荐）
# OPENAI_CUSTOM_MODEL_MAPPING='{"gemini-proxy":"gemini/gemini-1.5-pro","gpt4-proxy":"gemini/gemini-1.5-flash"}'

# === 使用示例 ===
# 1. 在图定义中调用标准模型：
#    "model": "openai_custom/gpt-4o"
#
# 2. 在图定义中调用映射模型：
#    "model": "openai_custom/gemini-proxy"  # 实际上会使用 gemini/gemini-1.5-pro 的能力

# === 其他可能的配置示例 ===

# Groq 配置示例
# OPENAI_CUSTOM_BASE_URL="https://api.groq.com/openai"
# OPENAI_CUSTOM_API_KEYS="gsk_your-groq-key-here"
# OPENAI_CUSTOM_MODEL_MAPPING='{"llama3-proxy":"gemini/gemini-1.5-pro","mixtral-8x7b":"gemini/gemini-1.5-flash"}'

# 本地服务配置示例
# OPENAI_CUSTOM_BASE_URL="http://localhost:11434"
# OPENAI_CUSTOM_API_KEYS="dummy-key"  # 某些本地服务可能不需要真实密钥
# OPENAI_CUSTOM_MODEL_MAPPING='{"local-llama":"gemini/gemini-1.5-pro"}'
